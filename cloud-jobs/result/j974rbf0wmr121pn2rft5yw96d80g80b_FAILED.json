{
  "recordId": "j974rbf0wmr121pn2rft5yw96d80g80b",
  "status": "FAILED",
  "error": "cannot reshape tensor of 0 elements into shape [0, -1, 1, 512] because the unspecified dimension size -1 can be any value and is ambiguous",
  "error_type": "RuntimeError",
  "traceback": "Traceback (most recent call last):\n  File \"/tmp/ipykernel_50664/1087773233.py\", line 206, in run_job\n    generate_frames(recordId, characters, emotions)\n  File \"/tmp/ipykernel_50664/1087773233.py\", line 153, in generate_frames\n    img = pipe(\n          ^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py\", line 1483, in __call__\n    image = self.vae.decode(latents, return_dict=False)[0]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n    return method(self, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\", line 323, in decode\n    decoded = self._decode(z).sample\n              ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\", line 294, in _decode\n    dec = self.decoder(z)\n          ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/vae.py\", line 300, in forward\n    sample = self.mid_block(sample, latent_embeds)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/unets/unet_2d_blocks.py\", line 745, in forward\n    hidden_states = attn(hidden_states, temb=temb)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/attention_processor.py\", line 605, in forward\n    return self.processor(\n           ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/diffusers/models/attention_processor.py\", line 2753, in __call__\n    query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: cannot reshape tensor of 0 elements into shape [0, -1, 1, 512] because the unspecified dimension size -1 can be any value and is ambiguous\n"
}